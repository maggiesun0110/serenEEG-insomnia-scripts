import numpy as np
from xgboost import XGBClassifier
from sklearn.feature_selection import RFE
from sklearn.model_selection import GroupShuffleSplit, cross_val_score
import joblib

# === Load combined dataset ===
data = np.load("../results/combined_9features.npz")
X, y, groups = data["features"], data["labels"], data["subject_ids"]

# === Base model ===
xgb = XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss', random_state=42)

# === RFE to select top 6 features ===
rfe = RFE(estimator=xgb, n_features_to_select=6)
X_selected = rfe.fit_transform(X, y)
print("Selected feature indices:", np.where(rfe.support_)[0])

# === Cross-validate with group split ===
gss = GroupShuffleSplit(n_splits=5, test_size=0.2, random_state=42)
scores = cross_val_score(xgb, X_selected, y, groups=groups, cv=gss)

print("CV Accuracy scores:", scores)
print("Mean accuracy:", scores.mean())

xgb.fit(X_selected, y)
joblib.dump(xgb, "../results/xgb_rfe_model.joblib")